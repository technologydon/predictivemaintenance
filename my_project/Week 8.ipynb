{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d125f7-6cc5-4e68-895a-1b39eb746a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Libraries (Leave as is)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gcsfs\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                           f1_score, roc_auc_score, roc_curve, confusion_matrix)\n",
    "\n",
    "import shap\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc2d03f0-a7a0-44c2-bda6-ff0d36151049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Dataset shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Loading (Leave as is)\n",
    "bucket_name = \"predictivemaintence\"\n",
    "file_path = \"predictive_maintenance.csv\"\n",
    "gcs_path = f\"gs://{bucket_name}/{file_path}\"\n",
    "\n",
    "try:\n",
    "    fs = gcsfs.GCSFileSystem()\n",
    "    df = pd.read_csv(gcs_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {gcs_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c686ccf-192c-4824-8751-c9b13b6f4622",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   UDI                      10000 non-null  int64  \n",
      " 1   Product ID               10000 non-null  object \n",
      " 2   Type                     10000 non-null  object \n",
      " 3   Air temperature [K]      10000 non-null  float64\n",
      " 4   Process temperature [K]  10000 non-null  float64\n",
      " 5   Rotational speed [rpm]   10000 non-null  int64  \n",
      " 6   Torque [Nm]              10000 non-null  float64\n",
      " 7   Tool wear [min]          10000 non-null  int64  \n",
      " 8   Target                   10000 non-null  int64  \n",
      " 9   Failure Type             10000 non-null  object \n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 781.4+ KB\n",
      "\n",
      "Original Data Head:\n",
      "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
      "0    1     M14860    M                298.1                    308.6   \n",
      "1    2     L47181    L                298.2                    308.7   \n",
      "2    3     L47182    L                298.1                    308.5   \n",
      "3    4     L47183    L                298.2                    308.6   \n",
      "4    5     L47184    L                298.2                    308.7   \n",
      "\n",
      "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
      "0                    1551         42.8                0       0   No Failure  \n",
      "1                    1408         46.3                3       0   No Failure  \n",
      "2                    1498         49.4                5       0   No Failure  \n",
      "3                    1433         39.5                7       0   No Failure  \n",
      "4                    1408         40.0                9       0   No Failure  \n",
      "\n",
      "Missing values before preprocessing:\n",
      "UDI                        0\n",
      "Product ID                 0\n",
      "Type                       0\n",
      "Air temperature [K]        0\n",
      "Process temperature [K]    0\n",
      "Rotational speed [rpm]     0\n",
      "Torque [Nm]                0\n",
      "Tool wear [min]            0\n",
      "Target                     0\n",
      "Failure Type               0\n",
      "dtype: int64\n",
      "\n",
      "Features identified:\n",
      "Categorical: ['Type']\n",
      "Numerical: ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
      "\n",
      "Target variable shape: (10000,)\n",
      "Features shape before encoding: (10000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initial Exploration & Basic Preprocessing (Leave as is)\n",
    "print(\"Original Data Info:\")\n",
    "df.info()\n",
    "print(\"\\nOriginal Data Head:\")\n",
    "print(df.head())\n",
    "print(\"\\nMissing values before preprocessing:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "features_to_drop = ['UDI', 'Product ID', 'Failure Type', 'Target']\n",
    "X = df.drop(columns=features_to_drop)\n",
    "y = df['Target']\n",
    "\n",
    "categorical_features = ['Type']\n",
    "numerical_features = X.drop(columns=categorical_features).columns.tolist()\n",
    "\n",
    "print(\"\\nFeatures identified:\")\n",
    "print(\"Categorical:\", categorical_features)\n",
    "print(\"Numerical:\", numerical_features)\n",
    "print(\"\\nTarget variable shape:\", y.shape)\n",
    "print(\"Features shape before encoding:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d50fda4e-600e-40d0-b514-66b6ee7dcd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into Train and Test sets:\n",
      "X_train shape: (8000, 6)\n",
      "X_test shape: (2000, 6)\n",
      "y_train shape: (8000,)\n",
      "y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train/Test Split (Leave as is)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Data split into Train and Test sets:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e2c4be4-283e-4793-8e4f-3cbabd6f50e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed feature names: ['num__Air temperature [K]', 'num__Process temperature [K]', 'num__Rotational speed [rpm]', 'num__Torque [Nm]', 'num__Tool wear [min]', 'cat__Type_H', 'cat__Type_L', 'cat__Type_M']\n",
      "\n",
      "Shapes after preprocessing:\n",
      "X_train_processed_df shape: (8000, 8)\n",
      "X_test_processed_df shape: (2000, 8)\n",
      "\n",
      "First 5 rows of processed training data:\n",
      "      num__Air temperature [K]  num__Process temperature [K]  \\\n",
      "4058                  0.998914                      0.604282   \n",
      "1221                 -1.505194                     -1.153260   \n",
      "6895                  0.498092                      1.077466   \n",
      "9863                 -0.553633                     -0.139294   \n",
      "8711                 -1.455112                     -1.018064   \n",
      "\n",
      "      num__Rotational speed [rpm]  num__Torque [Nm]  num__Tool wear [min]  \\\n",
      "4058                    -0.460607          0.718305             -0.843997   \n",
      "1221                    -0.775574          0.638456              0.382263   \n",
      "6895                    -1.007654          0.558607              0.460870   \n",
      "9863                    -0.709265          1.626586             -0.372359   \n",
      "8711                     1.070019         -1.128202             -0.906882   \n",
      "\n",
      "      cat__Type_H  cat__Type_L  cat__Type_M  \n",
      "4058          0.0          0.0          1.0  \n",
      "1221          0.0          0.0          1.0  \n",
      "6895          0.0          0.0          1.0  \n",
      "9863          0.0          1.0          0.0  \n",
      "8711          0.0          1.0          0.0  \n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Preprocessing Pipeline (Leave as is)\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "try:\n",
    "    feature_names_out = preprocessor.get_feature_names_out()\n",
    "    print(\"\\nProcessed feature names:\", feature_names_out.tolist())\n",
    "except AttributeError:\n",
    "    feature_names_out = numerical_features + \\\n",
    "                        preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()\n",
    "    print(\"\\nProcessed feature names (fallback):\", feature_names_out)\n",
    "\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed, columns=feature_names_out, index=X_train.index)\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=feature_names_out, index=X_test.index)\n",
    "\n",
    "print(\"\\nShapes after preprocessing:\")\n",
    "print(\"X_train_processed_df shape:\", X_train_processed_df.shape)\n",
    "print(\"X_test_processed_df shape:\", X_test_processed_df.shape)\n",
    "print(\"\\nFirst 5 rows of processed training data:\")\n",
    "print(X_train_processed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6254e238-c1e6-48a1-9342-0794ab4f0cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Baseline Logistic Regression Model ---\n",
      "\n",
      "--- Baseline Model Evaluation ---\n",
      "Accuracy: 0.9675\n",
      "Precision: 0.6363636363636364\n",
      "Recall: 0.10294117647058823\n",
      "F1-score: 0.17721518987341772\n",
      "AUC-ROC: 0.8993880160759956\n",
      "Confusion Matrix:\n",
      " [[1928    4]\n",
      " [  61    7]]\n",
      "\n",
      "Baseline model saved to predictive_maintenance_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Baseline Model (Logistic Regression) (Modified to add model saving)\n",
    "print(\"\\n--- Training Baseline Logistic Regression Model ---\")\n",
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train_processed_df, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_baseline = baseline_model.predict(X_test_processed_df)\n",
    "y_pred_proba_baseline = baseline_model.predict_proba(X_test_processed_df)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n--- Baseline Model Evaluation ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_baseline))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_baseline))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_baseline))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_baseline))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred_proba_baseline))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_baseline))\n",
    "\n",
    "# --- ADD THESE LINES TO SAVE THE MODEL ---\n",
    "import joblib\n",
    "joblib.dump(baseline_model, 'predictive_maintenance_model.pkl')\n",
    "print(\"\\nBaseline model saved to predictive_maintenance_model.pkl\")\n",
    "# ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846f6f5-912a-42a3-a048-8b0d9259835e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-17.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m128"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
